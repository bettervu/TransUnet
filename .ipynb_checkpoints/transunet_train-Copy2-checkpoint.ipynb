{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54b33739",
   "metadata": {},
   "source": [
    "# Run this code block to install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b319badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/KenzaB27/TransUnet.git\n",
    "# %cd TransUnet\n",
    "# !pip install -r requirements.txt \n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2dbece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/srinathramalingam/Desktop/codebase/TransUnet/TransUnet\n",
      "/Users/srinathramalingam/Desktop/codebase/TransUnet\n"
     ]
    }
   ],
   "source": [
    "%cd TransUnet\n",
    "import models.transunet as transunet\n",
    "import utils.visualize as visualize\n",
    "import experiments.config as conf\n",
    "import importlib\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efa3e23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import imageio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "from bp import Environment, String\n",
    "from focal_loss import BinaryFocalLoss\n",
    "from dTurk.generators import SemsegData\n",
    "from dTurk.builders import model_builder\n",
    "from tensorflow.keras import backend as K\n",
    "from dTurk.utils.clr_callback import CyclicLR\n",
    "from dTurk.metrics import MeanIoU, WeightedMeanIoU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from dTurk.loaders.dataset_loader import SemsegDatasetLoader\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from dTurk.augmentation.transforms import get_train_transform_policy, get_validation_transform_policy\n",
    "from dTurk.models.sm_models.losses import CategoricalCELoss, CategoricalFocalLoss, DiceLoss, JaccardLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcfd2ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from bp import Environment\n",
    "import TransUnet.experiments.config as conf\n",
    "from dTurk.utils.clr_callback import CyclicLR\n",
    "import TransUnet.models.transunet as transunet\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from train_helpers import dice_loss, mean_iou, oversampling, create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "001c8fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment()\n",
    "\n",
    "config = conf.get_transunet()\n",
    "config['image_size'] = 256\n",
    "config[\"filters\"] = 3\n",
    "config['n_skip'] = 3\n",
    "config['decoder_channels'] = [128, 64, 32, 16]\n",
    "config['resnet']['n_layers'] = (3,4,9,12)\n",
    "config['dropout'] = 0.1\n",
    "config['grid'] = (28,28)\n",
    "config[\"n_layers\"] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2a3a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"MACH-77-it3\"\n",
    "machine = \"local\"\n",
    "monitor = \"val_loss\"\n",
    "epochs = 75\n",
    "patience = 12\n",
    "batch_size = 32\n",
    "lr = 0.005\n",
    "train_augmentation_file = \"/Users/srinathramalingam/Desktop/codebase/dTurk/dTurk/augmentation/configs/light.yaml\"\n",
    "save_path = \"weights/TransUnet\"\n",
    "checkpoint_filepath = save_path + \"/checkpoint/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f29cc7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory = os.environ.get(\"BP_PATH_REMOTE\") + \"/datasets/semseg_base\" + \"/\" + dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee5324a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gpus not found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    tf.config.set_visible_devices(gpus[args_dict[\"gpu\"]], \"GPU\")\n",
    "except:\n",
    "    print(\"Gpus not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5873b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_names = [\n",
    "    dataset_directory + \"/train_labels/\" + i\n",
    "    for i in os.listdir(dataset_directory + \"/train_labels/\")\n",
    "    if i.endswith(\".png\")\n",
    "]\n",
    "val_input_names = [\n",
    "    dataset_directory + \"/val/\" + i for i in os.listdir(dataset_directory + \"/val/\") if i.endswith(\".png\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc45eb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 90/90 [00:00<00:00, 236.28it/s]\n",
      "/Users/srinathramalingam/opt/anaconda3/envs/bv2/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1800: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/Users/srinathramalingam/opt/anaconda3/envs/bv2/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1826: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "2022-06-29 18:30:51.409412: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_input_names = oversampling(train_input_names, machine, dataset, -1)\n",
    "train_ds_batched, val_ds_batched = create_dataset(train_input_names, val_input_names, train_augmentation=train_augmentation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb111b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = int(2.0 * len(train_input_names) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddc2792b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListWrapper([128, 64, 32, 16])\n"
     ]
    }
   ],
   "source": [
    "network = transunet.TransUnet(config, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab313d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.model.compile(optimizer=\"adam\", loss=dice_loss, metrics=mean_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be1031eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "cyclic_lr = CyclicLR(\n",
    "    base_lr=lr / 10.0,\n",
    "    max_lr=lr,\n",
    "    step_size=step_size,\n",
    "    mode=\"triangular2\",\n",
    "    cyclic_momentum=False,\n",
    "    max_momentum=False,\n",
    "    base_momentum=0.8,\n",
    ")\n",
    "callbacks.append(cyclic_lr)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=monitor,\n",
    "    mode=\"min\" if \"loss\" in monitor else \"max\",\n",
    "    patience=patience,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "callbacks.append(early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd80180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      " 8/11 [====================>.........] - ETA: 30s - loss: 0.6484 - mean_iou: 0.4120"
     ]
    }
   ],
   "source": [
    "history = network.model.fit(\n",
    "    train_ds_batched, epochs=epochs, validation_data=val_ds_batched, callbacks=[callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b62bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou = history.history[\"primary_mean_iou\"]\n",
    "val_iou = history.history[\"primary_mean_iou\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "df = pd.DataFrame(iou)\n",
    "df.columns = [\"mean_iou\"]\n",
    "df[\"val_mean_iou\"] = val_iou\n",
    "df[\"loss\"] = loss\n",
    "df[\"val_loss\"] = val_loss\n",
    "\n",
    "df.to_csv(\"TransUnet-logs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2532bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.model.load_weights(checkpoint_filepath)\n",
    "saved_model_path = args_dict[\"save_path\"] + \"/model\"\n",
    "network.model.save(saved_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
