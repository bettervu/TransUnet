{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb240ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from bp import Environment\n",
    "import TransUnet.experiments.config as conf\n",
    "from dTurk.utils.clr_callback import CyclicLR\n",
    "import TransUnet.models.transunet as transunet\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from train_helpers import dice_loss, mean_iou, oversampling, create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0746f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dTurk.models.sm_models as sm\n",
    "from dTurk.models.SM_UNet import SM_UNet_Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "797d2533",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21db878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"MACH-77-it3\"\n",
    "machine = \"local\"\n",
    "monitor = \"val_loss\"\n",
    "epochs = 75\n",
    "patience = 12\n",
    "batch_size = 32\n",
    "lr = 0.005\n",
    "train_augmentation_file = \"/Users/srinathramalingam/Desktop/codebase/dTurk/dTurk/augmentation/configs/light.yaml\"\n",
    "save_path = \"weights/Unet\"\n",
    "checkpoint_filepath = save_path + \"/checkpoint/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f29cc7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory = os.environ.get(\"BP_PATH_REMOTE\") + \"/datasets/semseg_base\" + \"/\" + dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ee5324a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gpus not found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "    tf.config.set_visible_devices(gpus[args_dict[\"gpu\"]], \"GPU\")\n",
    "except:\n",
    "    print(\"Gpus not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2539532",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_names = [\n",
    "    dataset_directory + \"/train_labels/\" + i\n",
    "    for i in os.listdir(dataset_directory + \"/train_labels/\")\n",
    "    if i.endswith(\".png\")\n",
    "]\n",
    "val_input_names = [\n",
    "    dataset_directory + \"/val/\" + i for i in os.listdir(dataset_directory + \"/val/\") if i.endswith(\".png\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd88678f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 90/90 [00:00<00:00, 216.12it/s]\n",
      "/Users/srinathramalingam/opt/anaconda3/envs/bv2/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1800: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/Users/srinathramalingam/opt/anaconda3/envs/bv2/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1826: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "2022-06-29 18:30:49.407913: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_input_names = oversampling(train_input_names, machine, dataset, -1)\n",
    "train_ds_batched, val_ds_batched = create_dataset(train_input_names, val_input_names, train_augmentation=train_augmentation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "637d3558",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = int(2.0 * len(train_input_names) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4d16dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = SM_UNet_Builder(\n",
    "    encoder_name='efficientnetv2-l',\n",
    "    input_shape=(256, 256, 3),\n",
    "    num_classes=3,\n",
    "    activation=\"softmax\",\n",
    "    train_encoder=False,\n",
    "    encoder_weights=\"imagenet\",\n",
    "    decoder_block_type=\"upsampling\",\n",
    "    head_dropout=0,  # dropout at head\n",
    "    dropout=0,  # dropout at feature extraction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92e0f027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/srinathramalingam/opt/anaconda3/envs/bv2/lib/python3.10/site-packages/tensorflow/python/training/tracking/util.py:1444: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.\n"
     ]
    }
   ],
   "source": [
    "model = builder.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cbdf0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=dice_loss, metrics=mean_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fcfbed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "cyclic_lr = CyclicLR(\n",
    "    base_lr=lr / 10.0,\n",
    "    max_lr=lr,\n",
    "    step_size=step_size,\n",
    "    mode=\"triangular2\",\n",
    "    cyclic_momentum=False,\n",
    "    max_momentum=False,\n",
    "    base_momentum=0.8,\n",
    ")\n",
    "callbacks.append(cyclic_lr)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=monitor,\n",
    "    mode=\"min\" if \"loss\" in monitor else \"max\",\n",
    "    patience=patience,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "callbacks.append(early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c336638c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "11/11 [==============================] - 391s 31s/step - loss: 0.5224 - mean_iou: 0.7493 - val_loss: 0.5063 - val_mean_iou: 0.7048\n",
      "Epoch 2/75\n",
      "11/11 [==============================] - 315s 27s/step - loss: 0.4751 - mean_iou: 0.9561 - val_loss: 0.5063 - val_mean_iou: 0.7049\n",
      "Epoch 3/75\n",
      "11/11 [==============================] - 303s 28s/step - loss: 0.4730 - mean_iou: 0.9556 - val_loss: 0.5060 - val_mean_iou: 0.7054\n",
      "Epoch 4/75\n",
      "11/11 [==============================] - 300s 27s/step - loss: 0.4701 - mean_iou: 0.9698 - val_loss: 0.5054 - val_mean_iou: 0.7049\n",
      "Epoch 5/75\n",
      "11/11 [==============================] - 282s 25s/step - loss: 0.4691 - mean_iou: 0.9696 - val_loss: 0.5060 - val_mean_iou: 0.7050\n",
      "Epoch 6/75\n",
      "11/11 [==============================] - 289s 26s/step - loss: 0.4685 - mean_iou: 0.9760 - val_loss: 0.5064 - val_mean_iou: 0.7069\n",
      "Epoch 7/75\n",
      "11/11 [==============================] - 295s 27s/step - loss: 0.4681 - mean_iou: 0.9773 - val_loss: 0.5052 - val_mean_iou: 0.7187\n",
      "Epoch 8/75\n",
      "11/11 [==============================] - 295s 27s/step - loss: 0.4692 - mean_iou: 0.9744 - val_loss: 0.4834 - val_mean_iou: 0.8739\n",
      "Epoch 9/75\n",
      "11/11 [==============================] - 268s 24s/step - loss: 0.4684 - mean_iou: 0.9742 - val_loss: 0.4985 - val_mean_iou: 0.7498\n",
      "Epoch 10/75\n",
      "11/11 [==============================] - 274s 25s/step - loss: 0.4695 - mean_iou: 0.9686 - val_loss: 0.4993 - val_mean_iou: 0.7466\n",
      "Epoch 11/75\n",
      "11/11 [==============================] - 320s 29s/step - loss: 0.4683 - mean_iou: 0.9773 - val_loss: 0.4963 - val_mean_iou: 0.7647\n",
      "Epoch 12/75\n",
      "11/11 [==============================] - 278s 25s/step - loss: 0.4678 - mean_iou: 0.9786 - val_loss: 0.4707 - val_mean_iou: 0.9601\n",
      "Epoch 13/75\n",
      "11/11 [==============================] - 283s 25s/step - loss: 0.4680 - mean_iou: 0.9766 - val_loss: 0.4697 - val_mean_iou: 0.9662\n",
      "Epoch 14/75\n",
      "11/11 [==============================] - 278s 23s/step - loss: 0.4678 - mean_iou: 0.9798 - val_loss: 0.4692 - val_mean_iou: 0.9689\n",
      "Epoch 15/75\n",
      "11/11 [==============================] - 241s 22s/step - loss: 0.4677 - mean_iou: 0.9798 - val_loss: 0.4690 - val_mean_iou: 0.9698\n",
      "Epoch 16/75\n",
      "11/11 [==============================] - 240s 22s/step - loss: 0.4679 - mean_iou: 0.9782 - val_loss: 0.4690 - val_mean_iou: 0.9698\n",
      "Epoch 17/75\n",
      "11/11 [==============================] - 239s 22s/step - loss: 0.4687 - mean_iou: 0.9664 - val_loss: 0.4690 - val_mean_iou: 0.9697\n",
      "Epoch 18/75\n",
      "11/11 [==============================] - 242s 22s/step - loss: 0.4678 - mean_iou: 0.9784 - val_loss: 0.4705 - val_mean_iou: 0.9652\n",
      "Epoch 19/75\n",
      "11/11 [==============================] - 251s 23s/step - loss: 0.4676 - mean_iou: 0.9795 - val_loss: 0.4690 - val_mean_iou: 0.9698\n",
      "Epoch 20/75\n",
      "11/11 [==============================] - 242s 22s/step - loss: 0.4680 - mean_iou: 0.9734 - val_loss: 0.4688 - val_mean_iou: 0.9703\n",
      "Epoch 21/75\n",
      "11/11 [==============================] - 250s 23s/step - loss: 0.4681 - mean_iou: 0.9767 - val_loss: 0.4689 - val_mean_iou: 0.9687\n",
      "Epoch 22/75\n",
      "11/11 [==============================] - 254s 23s/step - loss: 0.4676 - mean_iou: 0.9773 - val_loss: 0.4687 - val_mean_iou: 0.9699\n",
      "Epoch 23/75\n",
      "11/11 [==============================] - 261s 24s/step - loss: 0.4675 - mean_iou: 0.9789 - val_loss: 0.4685 - val_mean_iou: 0.9711\n",
      "Epoch 24/75\n",
      "11/11 [==============================] - 248s 22s/step - loss: 0.4674 - mean_iou: 0.9779 - val_loss: 0.4686 - val_mean_iou: 0.9709\n",
      "Epoch 25/75\n",
      "11/11 [==============================] - 251s 23s/step - loss: 0.4673 - mean_iou: 0.9794 - val_loss: 0.4685 - val_mean_iou: 0.9715\n",
      "Epoch 26/75\n",
      "11/11 [==============================] - 240s 22s/step - loss: 0.4676 - mean_iou: 0.9746 - val_loss: 0.4687 - val_mean_iou: 0.9696\n",
      "Epoch 27/75\n",
      "11/11 [==============================] - 246s 22s/step - loss: 0.4743 - mean_iou: 0.9375 - val_loss: 0.4691 - val_mean_iou: 0.9671\n",
      "Epoch 28/75\n",
      "11/11 [==============================] - 240s 22s/step - loss: 0.4676 - mean_iou: 0.9781 - val_loss: 0.4702 - val_mean_iou: 0.9565\n",
      "Epoch 29/75\n",
      "11/11 [==============================] - 241s 22s/step - loss: 0.4677 - mean_iou: 0.9772 - val_loss: 0.4698 - val_mean_iou: 0.9591\n",
      "Epoch 30/75\n",
      "11/11 [==============================] - 249s 23s/step - loss: 0.4677 - mean_iou: 0.9774 - val_loss: 0.4688 - val_mean_iou: 0.9678\n",
      "Epoch 31/75\n",
      "11/11 [==============================] - 246s 22s/step - loss: 0.4674 - mean_iou: 0.9780 - val_loss: 0.4688 - val_mean_iou: 0.9673\n",
      "Epoch 32/75\n",
      "11/11 [==============================] - 241s 22s/step - loss: 0.4674 - mean_iou: 0.9795 - val_loss: 0.4686 - val_mean_iou: 0.9695\n",
      "Epoch 33/75\n",
      "11/11 [==============================] - 243s 22s/step - loss: 0.4673 - mean_iou: 0.9802 - val_loss: 0.4685 - val_mean_iou: 0.9700\n",
      "Epoch 34/75\n",
      "11/11 [==============================] - 252s 23s/step - loss: 0.4673 - mean_iou: 0.9801 - val_loss: 0.4685 - val_mean_iou: 0.9702\n",
      "Epoch 35/75\n",
      "11/11 [==============================] - 261s 24s/step - loss: 0.4675 - mean_iou: 0.9787 - val_loss: 0.4685 - val_mean_iou: 0.9703\n",
      "Epoch 36/75\n",
      "11/11 [==============================] - 251s 23s/step - loss: 0.4674 - mean_iou: 0.9805 - val_loss: 0.4684 - val_mean_iou: 0.9711\n",
      "Epoch 37/75\n",
      "11/11 [==============================] - 251s 22s/step - loss: 0.4672 - mean_iou: 0.9809 - val_loss: 0.4684 - val_mean_iou: 0.9715\n",
      "Epoch 38/75\n",
      "11/11 [==============================] - 178s 15s/step - loss: 0.4680 - mean_iou: 0.9763 - val_loss: 0.4682 - val_mean_iou: 0.9727\n",
      "Epoch 39/75\n",
      "11/11 [==============================] - 155s 14s/step - loss: 0.4672 - mean_iou: 0.9810 - val_loss: 0.4683 - val_mean_iou: 0.9729\n",
      "Epoch 40/75\n",
      "11/11 [==============================] - 152s 14s/step - loss: 0.4672 - mean_iou: 0.9807 - val_loss: 0.4682 - val_mean_iou: 0.9730\n",
      "Epoch 41/75\n",
      "11/11 [==============================] - 153s 14s/step - loss: 0.4671 - mean_iou: 0.9812 - val_loss: 0.4681 - val_mean_iou: 0.9730\n",
      "Epoch 42/75\n",
      "11/11 [==============================] - 152s 14s/step - loss: 0.4681 - mean_iou: 0.9705 - val_loss: 0.4681 - val_mean_iou: 0.9733\n",
      "Epoch 43/75\n",
      "11/11 [==============================] - 153s 14s/step - loss: 0.4672 - mean_iou: 0.9804 - val_loss: 0.4686 - val_mean_iou: 0.9728\n",
      "Epoch 44/75\n",
      "11/11 [==============================] - 152s 14s/step - loss: 0.4671 - mean_iou: 0.9806 - val_loss: 0.4681 - val_mean_iou: 0.9735\n",
      "Epoch 45/75\n",
      "11/11 [==============================] - 156s 14s/step - loss: 0.4672 - mean_iou: 0.9772 - val_loss: 0.4680 - val_mean_iou: 0.9737\n",
      "Epoch 46/75\n",
      "11/11 [==============================] - 156s 14s/step - loss: 0.4672 - mean_iou: 0.9786 - val_loss: 0.4680 - val_mean_iou: 0.9736\n",
      "Epoch 47/75\n",
      "11/11 [==============================] - 153s 14s/step - loss: 0.4671 - mean_iou: 0.9812 - val_loss: 0.4680 - val_mean_iou: 0.9737\n",
      "Epoch 48/75\n",
      "11/11 [==============================] - 154s 14s/step - loss: 0.4672 - mean_iou: 0.9808 - val_loss: 0.4680 - val_mean_iou: 0.9738\n",
      "Epoch 49/75\n",
      "11/11 [==============================] - 154s 14s/step - loss: 0.4676 - mean_iou: 0.9713 - val_loss: 0.4680 - val_mean_iou: 0.9739\n",
      "Epoch 50/75\n",
      "11/11 [==============================] - 153s 14s/step - loss: 0.4672 - mean_iou: 0.9785 - val_loss: 0.4698 - val_mean_iou: 0.9699\n",
      "Epoch 51/75\n",
      "11/11 [==============================] - 154s 14s/step - loss: 0.4673 - mean_iou: 0.9804 - val_loss: 0.4681 - val_mean_iou: 0.9730\n",
      "Epoch 52/75\n",
      "11/11 [==============================] - 161s 14s/step - loss: 0.4671 - mean_iou: 0.9799 - val_loss: 0.4681 - val_mean_iou: 0.9732\n",
      "Epoch 53/75\n",
      "11/11 [==============================] - 169s 15s/step - loss: 0.4671 - mean_iou: 0.9799 - val_loss: 0.4680 - val_mean_iou: 0.9738\n",
      "Epoch 54/75\n",
      "11/11 [==============================] - 162s 15s/step - loss: 0.4673 - mean_iou: 0.9769 - val_loss: 0.4680 - val_mean_iou: 0.9738\n",
      "Epoch 55/75\n",
      "11/11 [==============================] - 162s 15s/step - loss: 0.4680 - mean_iou: 0.9736 - val_loss: 0.4757 - val_mean_iou: 0.9604\n",
      "Epoch 56/75\n",
      "11/11 [==============================] - 158s 14s/step - loss: 0.4672 - mean_iou: 0.9787 - val_loss: 0.4683 - val_mean_iou: 0.9727\n",
      "Epoch 57/75\n",
      "11/11 [==============================] - 152s 14s/step - loss: 0.4671 - mean_iou: 0.9809 - val_loss: 0.4680 - val_mean_iou: 0.9735\n",
      "Epoch 58/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 171s 16s/step - loss: 0.4670 - mean_iou: 0.9817 - val_loss: 0.4679 - val_mean_iou: 0.9738\n",
      "Epoch 59/75\n",
      "11/11 [==============================] - 166s 14s/step - loss: 0.4674 - mean_iou: 0.9748 - val_loss: 0.4679 - val_mean_iou: 0.9738\n",
      "Epoch 60/75\n",
      "11/11 [==============================] - 166s 15s/step - loss: 0.4674 - mean_iou: 0.9767 - val_loss: 0.4681 - val_mean_iou: 0.9725\n",
      "Epoch 61/75\n",
      "11/11 [==============================] - 233s 22s/step - loss: 0.4671 - mean_iou: 0.9786 - val_loss: 0.4683 - val_mean_iou: 0.9712\n",
      "Epoch 62/75\n",
      "11/11 [==============================] - 294s 24s/step - loss: 0.4671 - mean_iou: 0.9792 - val_loss: 0.4682 - val_mean_iou: 0.9722\n",
      "Epoch 63/75\n",
      "11/11 [==============================] - 455s 42s/step - loss: 0.4670 - mean_iou: 0.9816 - val_loss: 0.4681 - val_mean_iou: 0.9727\n",
      "Epoch 64/75\n",
      "11/11 [==============================] - 511s 46s/step - loss: 0.4670 - mean_iou: 0.9819 - val_loss: 0.4680 - val_mean_iou: 0.9737\n",
      "Epoch 65/75\n",
      "11/11 [==============================] - 533s 48s/step - loss: 0.4670 - mean_iou: 0.9804 - val_loss: 0.4679 - val_mean_iou: 0.9740\n",
      "Epoch 66/75\n",
      "11/11 [==============================] - 513s 46s/step - loss: 0.4670 - mean_iou: 0.9817 - val_loss: 0.4679 - val_mean_iou: 0.9741\n",
      "Epoch 67/75\n",
      "11/11 [==============================] - 477s 43s/step - loss: 0.4671 - mean_iou: 0.9777 - val_loss: 0.4679 - val_mean_iou: 0.9739\n",
      "Epoch 68/75\n",
      "11/11 [==============================] - 472s 43s/step - loss: 0.4672 - mean_iou: 0.9736 - val_loss: 0.4679 - val_mean_iou: 0.9739\n",
      "Epoch 69/75\n",
      "11/11 [==============================] - 492s 45s/step - loss: 0.4671 - mean_iou: 0.9776 - val_loss: 0.4900 - val_mean_iou: 0.8062\n",
      "Epoch 70/75\n",
      "11/11 [==============================] - 472s 43s/step - loss: 0.4674 - mean_iou: 0.9749 - val_loss: 0.4687 - val_mean_iou: 0.9706\n",
      "Epoch 71/75\n",
      "11/11 [==============================] - 521s 47s/step - loss: 0.4672 - mean_iou: 0.9777 - val_loss: 0.4682 - val_mean_iou: 0.9717\n",
      "Epoch 72/75\n",
      "11/11 [==============================] - 500s 45s/step - loss: 0.4672 - mean_iou: 0.9764 - val_loss: 0.4683 - val_mean_iou: 0.9704\n",
      "Epoch 73/75\n",
      "11/11 [==============================] - 491s 44s/step - loss: 0.4676 - mean_iou: 0.9775 - val_loss: 0.4697 - val_mean_iou: 0.9590\n",
      "Epoch 74/75\n",
      "11/11 [==============================] - 504s 46s/step - loss: 0.4683 - mean_iou: 0.9679 - val_loss: 0.4714 - val_mean_iou: 0.9437\n",
      "Epoch 75/75\n",
      "11/11 [==============================] - 494s 44s/step - loss: 0.4679 - mean_iou: 0.9757 - val_loss: 0.4684 - val_mean_iou: 0.9692\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds_batched, epochs=epochs, validation_data=val_ds_batched, callbacks=[callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b62bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou = history.history[\"mean_iou\"]\n",
    "val_iou = history.history[\"val_mean_iou\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "df = pd.DataFrame(iou)\n",
    "df.columns = [\"mean_iou\"]\n",
    "df[\"val_mean_iou\"] = val_iou\n",
    "df[\"loss\"] = loss\n",
    "df[\"val_loss\"] = val_loss\n",
    "\n",
    "df.to_csv(\"Unet-logs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4aacc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 350). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/Unet/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weights/Unet/model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(checkpoint_filepath+'/Unet.h5')\n",
    "model.load_weights(checkpoint_filepath+'/Unet.h5')\n",
    "saved_model_path = save_path + \"/model\"\n",
    "model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b91107e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dTurk.models.sm_models as sm\n",
    "from dTurk.models.SM_UNet import SM_UNet_Builder\n",
    "\n",
    "builder = SM_UNet_Builder(\n",
    "    encoder_name='efficientnetv2-l',\n",
    "    input_shape=(256, 256, 3),\n",
    "    num_classes=3,\n",
    "    activation=\"softmax\",\n",
    "    train_encoder=False,\n",
    "    encoder_weights=\"imagenet\",\n",
    "    decoder_block_type=\"upsampling\",\n",
    "    head_dropout=0,  # dropout at head\n",
    "    dropout=0,  # dropout at feature extraction\n",
    ")\n",
    "model2 = builder.build_model()\n",
    "model2.load_weights(\"/Users/srinathramalingam/Desktop/codebase/TransUnet/weights/Unet/checkpoint/Unet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4248ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image, model1, model2, file):\n",
    "    img = cv2.imread(image)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    img = np.array(img)/255\n",
    "    img = img.reshape((1,256,256,3))\n",
    "    prediction1 = model1.predict(img)\n",
    "    prediction1 = tf.clip_by_value(prediction1, 0.0, 1.0)\n",
    "    prediction2 = model2.predict(img)\n",
    "    prediction2 = tf.clip_by_value(prediction2, 0.0, 1.0)\n",
    "    pred1 = prediction1 * 255\n",
    "    pred1 = np.array(prediction1).reshape((256,256,3))\n",
    "    pred2 = prediction2 * 255\n",
    "    pred2 = np.array(prediction2).reshape((256,256,3))\n",
    "    img = img.reshape((256,256,3))\n",
    "    return img, pred1, pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c50a51f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_names = [\"/Users/srinathramalingam/Desktop/codebase/Jupyter_predictions_Nearspace/MACH-77-it2/val/images/\" + i for i in os.listdir(\"/Users/srinathramalingam/Desktop/codebase/Jupyter_predictions_Nearspace/MACH-77-it2/val/images\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b81f2772",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(val_input_names)):\n\u001b[0;32m----> 2\u001b[0m     img, pred1, pred2 \u001b[38;5;241m=\u001b[39m predict(val_input_names[file], \u001b[43mnetwork\u001b[49m\u001b[38;5;241m.\u001b[39mmodel, model2, file)\n\u001b[1;32m      4\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(img)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'network' is not defined"
     ]
    }
   ],
   "source": [
    "for file in range(len(val_input_names)):\n",
    "    img, pred1, pred2 = predict(val_input_names[file], network.model, model2, file)\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(pred1)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pred2)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49518f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
